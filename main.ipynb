{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing With Transformers ❤\n",
        "\n"
      ],
      "metadata": {
        "id": "I8fy9_O7ys6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a piece of text, like the following made-up customer feed‐\n",
        "back about a certain online order:"
      ],
      "metadata": {
        "id": "9MrtgwEnGpja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure\n",
        "from your online store in Germany. Unfortunately, when I opened the package,\n",
        "I discovered to my horror that I had been sent an action figure of Megatron\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ],
      "metadata": {
        "id": "pxiruZjDGkD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification :**"
      ],
      "metadata": {
        "id": "-ezLRaR7ym1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first time you run this code you’ll see a few progress bars appear because the\n",
        "pipeline automatically downloads the model weights from the Hugging Face Hub."
      ],
      "metadata": {
        "id": "Jfy2Rb370iho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfJWO5xKJ2hS"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first time you run this code you’ll see a few progress bars appear because the\n",
        "pipeline automatically downloads the model weights from the Hugging Face Hub.\n",
        "The second time you instantiate the pipeline, the library will notice that you’ve\n",
        "already downloaded the weights and will use the cached version instead. By default,\n",
        "the text-classification pipeline uses a model that’s designed for sentiment analy‐\n",
        "sis, but it also supports multiclass and multilabel classification"
      ],
      "metadata": {
        "id": "367IxEcPHPcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "outputs = classifier(text)\n",
        "pd.DataFrame(outputs)"
      ],
      "metadata": {
        "id": "_VD1CZWS0g_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case the model is very confident that the text has a negative sentiment, which\n",
        "makes sense given that we’re dealing with a complaint from an angry customer! Note\n",
        "that for sentiment analysis tasks the pipeline only returns one of the POSITIVE or NEG\n",
        "ATIVE labels, since the other can be inferred by computing 1-score.\n",
        "Let’s now take a look at another common task, identifying named entities in text."
      ],
      "metadata": {
        "id": "EIM0M5tvHJtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Named Entity Recognition**"
      ],
      "metadata": {
        "id": "xffHXrOyH_V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the sentiment of customer feedback is a good first step, but you often want\n",
        "to know if the feedback was about a particular item or service. In NLP, real-world\n",
        "objects like products, places, and people are called named entities, and extracting\n",
        "them from text is called named entity recognition (NER). We can apply NER by load‐\n",
        "ing the corresponding pipeline and feeding our customer review to it:"
      ],
      "metadata": {
        "id": "AVa9MRW0IUnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "outputs = ner_tagger(text)\n",
        "pd.DataFrame(outputs)"
      ],
      "metadata": {
        "id": "mrfHnC_UHKzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the pipeline detected all the entities and also assigned a category\n",
        "such as ORG (organization), LOC (location), or PER (person) to each of them. Here we\n",
        "used the aggregation_strategy argument to group the words according to the mod‐\n",
        "el’s predictions. For example, the entity “Optimus Prime” is composed of two words,\n",
        "but is assigned a single category: MISC (miscellaneous). The scores tell us how confi‐\n",
        "dent the model was about the entities it identified. We can see that it was least confi‐\n",
        "dent about “Decepticons” and the first occurrence of “Megatron”, both of which it\n",
        "failed to group as a single entity."
      ],
      "metadata": {
        "id": "u9pz4N0bRCrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting all the named entities in a text is nice, but sometimes we would like to ask\n",
        "more targeted questions. This is where we can use question answering."
      ],
      "metadata": {
        "id": "xhH0iEc9RIh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering**"
      ],
      "metadata": {
        "id": "b0xISjZHRLpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see what we get when we ask a specific\n",
        "question about our customer feedback:"
      ],
      "metadata": {
        "id": "vZS5TRt2Mb3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = pipeline(\"question-answering\")\n",
        "question = \"What does the customer want?\"\n",
        "outputs = reader(question=question, context=text)\n",
        "pd.DataFrame([outputs])"
      ],
      "metadata": {
        "id": "fx7V4WQMRDPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The passage explains **extractive question answering**, where the answer is directly pulled from the text using start and end character indices. This method helps quickly extract relevant information from customer feedback. However, when faced with a large volume of lengthy complaints, an **automatic summarization model** might be more efficient."
      ],
      "metadata": {
        "id": "_yjm8h9qTybj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarization**"
      ],
      "metadata": {
        "id": "CTOQhOFSTzyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text summarization aims to condense long texts into shorter versions while retaining essential information. This task is more complex than others since it requires generating coherent text. A summarization pipeline can be set up as follows."
      ],
      "metadata": {
        "id": "DZ-61K6VUW3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n"
      ],
      "metadata": {
        "id": "A0Ix7cwAUQb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
        "print(outputs[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "500jmTEhU90q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model generated a good summary, capturing the essence of the issue and identifying the author. Additionally, by passing keyword arguments like **max_length**, we can tweak the outputs at runtime."
      ],
      "metadata": {
        "id": "l02y3zVDVlW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But what happens when you get feedback that is in a language you don’t understand?\n"
      ],
      "metadata": {
        "id": "WLlxbkDmVtVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Translation**"
      ],
      "metadata": {
        "id": "ZFEjCOy1Vo6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s use a translation pipeline to translate an English text to German:"
      ],
      "metadata": {
        "id": "7_Kr6qeaWFsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_en_to_de\",model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yk2bUQw8VxYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
        "print(outputs[0]['translation_text'])"
      ],
      "metadata": {
        "id": "wcKX07ZrV4wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model produced an accurate translation, correctly using formal German pronouns like \"Ihrem\" and \"Sie.\" It also demonstrates how to override the default model in the pipeline to choose the best one for your needs, with thousands of language models available on the Hugging Face Hub."
      ],
      "metadata": {
        "id": "aH88KB8EWRhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Generation**"
      ],
      "metadata": {
        "id": "4m67L5RcWSIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say you would like to be able to provide faster replies to customer feedback"
      ],
      "metadata": {
        "id": "ksBbkg-VWZAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n"
      ],
      "metadata": {
        "id": "-Nq_rF1rWZg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
        "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
        "outputs = generator(prompt, max_length=200)\n",
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "id": "k7FrzeJAWhJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The models used in this chapter are publicly available and pre-fine-tuned, but in upcoming chapters, you'll learn how to fine-tune models on your own data."
      ],
      "metadata": {
        "id": "LARgrt67XCPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a model is just one part of an NLP project,efficiently processing data, sharing results, and ensuring reproducibility are also crucial. Fortunately, Transformers is supported by a wide ecosystem of tools that facilitate the modern machine learning workflow."
      ],
      "metadata": {
        "id": "RHsJ136daHuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Hugging Face Ecosystem**"
      ],
      "metadata": {
        "id": "ZdnT-sy0aKoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What started with Transformers has expanded into a comprehensive ecosystem with libraries and tools to speed up NLP and machine learning projects. The Hugging Face ecosystem consists of libraries for code and the Hub for pretrained models, datasets, evaluation scripts, and more. This section briefly introduces the components, skipping Transformers as it has already been discussed and will be explored further in the book."
      ],
      "metadata": {
        "id": "vMGkS4iWaT_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread('/content/hfeco.png')\n",
        "\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2_imshow(image_rgb)\n"
      ],
      "metadata": {
        "id": "KeGYHtpUd3GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Hugging Face Hub**\n"
      ],
      "metadata": {
        "id": "Xbd_9EM2eDQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning is a key driver of transformers' success, enabling the reuse of pretrained models for new tasks."
      ],
      "metadata": {
        "id": "S09rPTGCfAd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "img1 = cv2.imread('/content/hub.png')\n",
        "img2 = cv2.imread('/content/cards.png')\n",
        "\n",
        "\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img1)\n",
        "plt.title(\"Hugging Face Hub\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img2)\n",
        "plt.title(\"Model/Dataset Cards\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lS7xZbwfT83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hugging Face Hub simplifies this by offering over 20,000 models, with filters for tasks, frameworks, and datasets to help users find and load models easily. In addition to model weights, the Hub provides datasets, evaluation scripts, and documentation (model and dataset cards). A standout feature is the ability to test models directly through interactive widgets."
      ],
      "metadata": {
        "id": "MGD-jdGAUi8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch and TensorFlow also offer hubs of their own and are\n",
        "worth checking out if a particular model or dataset is not available\n",
        "on the Hugging Face Hub.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Befn9sojUnrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face Tokenizers**\n",
        "Handles text tokenization, i.e., splitting text into small pieces (tokens).\n",
        "\n",
        "Extremely fast due to its Rust-based backend.\n",
        "\n",
        "Takes care of preprocessing and postprocessing steps like input normalization and output formatting."
      ],
      "metadata": {
        "id": "JAlZgEgYUzf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face Datasets**\n",
        "Simplifies the loading and preprocessing of datasets.\n",
        "\n",
        "Offers access to thousands of datasets from the Hugging Face Hub.\n",
        "\n",
        "Avoids memory issues using memory mapping.\n",
        "\n",
        "Includes standard metrics scripts to make evaluations reproducible and reliable."
      ],
      "metadata": {
        "id": "IV1Y8xQWW9DX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face Accelerate**\n",
        "Makes training code portable across different environments (laptops, clusters, GPUs).\n",
        "\n",
        "Automates technical parts of the training process: device placement, mixed precision, multi-GPU training, etc.\n",
        "\n",
        "Helps you write simpler training loops that adapt to various computing infrastructures."
      ],
      "metadata": {
        "id": "Mlbla8EHX6Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Challenges with Transformers**\n",
        "Transformers are powerful but not flawless. Key challenges include:\n",
        "\n",
        "- Language limitations: Most models focus on English; other languages are underrepresented.\n",
        "\n",
        "- Data needs: Transformers still require a lot of labeled data.\n",
        "\n",
        "- Handling long texts: Performance drops with very long documents due to high resource usage.\n",
        "\n",
        "- Lack of interpretability: It's hard to understand how or why a model makes a decision.\n",
        "\n",
        "- Bias in models: Pretraining on internet data can introduce harmful social biases."
      ],
      "metadata": {
        "id": "CN6N-MnzYAO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "In this notebook, we’ve explored the foundational concepts of natural language processing (NLP) with transformers, as introduced in Chapter 1 of *Natural Language Processing with Transformers* by Hugging Face. We have seen how transformer models revolutionize NLP tasks through their ability to handle complex tasks like text generation, translation, and summarization with remarkable efficiency. Additionally, we’ve examined the Hugging Face ecosystem, which provides powerful libraries like Transformers, Tokenizers, and Datasets, as well as the Hugging Face Hub for easy access to pretrained models and datasets.\n",
        "\n",
        "However, as we move forward, it's important to recognize the challenges associated with transformers, such as language limitations, data availability, handling long documents, opacity, and inherent biases in models. These challenges present opportunities for further exploration and innovation, and the book provides valuable insights and techniques to address them.\n",
        "\n",
        "Overall, the chapter has laid a strong foundation for understanding the transformative potential of transformers in NLP, and in the following chapters, we will dive deeper into practical solutions and applications in this rapidly evolving field.\n",
        "\n",
        "**Get ready for the next chapter!**"
      ],
      "metadata": {
        "id": "2BW8VmerYHcu"
      }
    }
  ]
}